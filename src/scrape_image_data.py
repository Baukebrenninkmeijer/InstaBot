
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/1_scrape_image_data.ipynb

import subprocess
import os
import pandas as pd
import json
import glob
import pickle
import spacy
import time
import cv2
import datetime
import logging
import numpy as np
from PIL import Image
from imagehash import average_hash
from InstagramAPI import InstagramAPI
# from keras.preprocessing.sequence import pad_sequences
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from skimage import io
from tqdm import tqdm, tqdm_notebook
from functools import partial
import instagram_scraper
import six
import sys
sys.path.append('src')
import lib


tqdm.pandas()

logger = logging.getLogger(__name__)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s %(name)-s %(levelname)-s : %(message)s')
fh = logging.FileHandler('logs/retrieve_data.log', encoding='utf-8')
fh.setLevel(logging.DEBUG)
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)
logger.addHandler(fh)

nlp = spacy.load("en")
artefacts_path = 'artefacts'
N_IMAGES = 30
city = lib.config['loc']['city']

io_method = lib.DatabaseIO() #CsvIO
read_data = io_method.read_data

write_data = io_method.write_data


def pad_sequences(sequences, maxlen=None, dtype='int32',
                  padding='pre', truncating='pre', value=0.):
    """Pads sequences to the same length.

    This function transforms a list of
    `num_samples` sequences (lists of integers)
    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.
    `num_timesteps` is either the `maxlen` argument if provided,
    or the length of the longest sequence otherwise.

    Sequences that are shorter than `num_timesteps`
    are padded with `value` at the end.

    Sequences longer than `num_timesteps` are truncated
    so that they fit the desired length.
    The position where padding or truncation happens is determined by
    the arguments `padding` and `truncating`, respectively.

    Pre-padding is the default.

    # Arguments
        sequences: List of lists, where each element is a sequence.
        maxlen: Int, maximum length of all sequences.
        dtype: Type of the output sequences.
            To pad sequences with variable length strings, you can use `object`.
        padding: String, 'pre' or 'post':
            pad either before or after each sequence.
        truncating: String, 'pre' or 'post':
            remove values from sequences larger than
            `maxlen`, either at the beginning or at the end of the sequences.
        value: Float or String, padding value.

    # Returns
        x: Numpy array with shape `(len(sequences), maxlen)`

    # Raises
        ValueError: In case of invalid values for `truncating` or `padding`,
            or in case of invalid shape for a `sequences` entry.
    """
    if not hasattr(sequences, '__len__'):
        raise ValueError('`sequences` must be iterable.')
    lengths = []
    for x in sequences:
        if not hasattr(x, '__len__'):
            raise ValueError('`sequences` must be a list of iterables. '
                             'Found non-iterable: ' + str(x))
        lengths.append(len(x))

    num_samples = len(sequences)
    if maxlen is None:
        maxlen = np.max(lengths)

    # take the sample shape from the first non empty sequence
    # checking for consistency in the main loop below.
    sample_shape = tuple()
    for s in sequences:
        if len(s) > 0:
            sample_shape = np.asarray(s).shape[1:]
            break

    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(dtype, np.unicode_)
    if isinstance(value, six.string_types) and dtype != object and not is_dtype_str:
        raise ValueError("`dtype` {} is not compatible with `value`'s type: {}\n"
                         "You should set `dtype=object` for variable length strings."
                         .format(dtype, type(value)))

    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)
    for idx, s in enumerate(sequences):
        if not len(s):
            continue  # empty list/array was found
        if truncating == 'pre':
            trunc = s[-maxlen:]
        elif truncating == 'post':
            trunc = s[:maxlen]
        else:
            raise ValueError('Truncating type "%s" '
                             'not understood' % truncating)

        # check `trunc` has expected shape
        trunc = np.asarray(trunc, dtype=dtype)
        if trunc.shape[1:] != sample_shape:
            raise ValueError('Shape of sample %s of sequence at position %s '
                             'is different from expected shape %s' %
                             (trunc.shape[1:], idx, sample_shape))

        if padding == 'post':
            x[idx, :len(trunc)] = trunc
        elif padding == 'pre':
            x[idx, -len(trunc):] = trunc
        else:
            raise ValueError('Padding type "%s" not understood' % padding)
    return x


def get_historic_data():
    return io_method.read_data('metadata')


def write_historic_metadata(df: pd.DataFrame):
    logger.info('Saving historic metadata...')
    io_method.write_data(df, 'metadata')
    logger.info('Done.')


def get_train_data():
    return io_method.read_data('metadata_train')


def get_image_hashes(metadata):
    image_hashes = {}
    hash_list = []
    assert metadata is not None, f'Metadata is None. Make sure there is some data'
    for i, row in tqdm_notebook(metadata.iterrows(), total=len(metadata)):
        image_path = f'ig_images/{row.username}/{row.shortcode}.jpg'
        hashed = str(average_hash(Image.open(image_path)))
        hash_list.append(hashed)
    return hash_list


def get_new_metadata(historic_data: pd.DataFrame = None):
    if historic_data is None: historic_data = pd.DataFrame(columns=['shortcode'])
    api = lib.getApi()
    metadata = []
    userinfo_columns = ['pk', 'username', 'full_name', 'follower_count', 'following_count', 'is_private',
                        'biography']
    userinfo = pd.DataFrame(columns=userinfo_columns)
    for filename in glob.iglob('ig_images/**/*.json'):
        with open(filename, 'rb') as f:
            d = json.load(f)
            api.getUsernameInfo(d['GraphImages'][0]['owner']['id'])
            userinfo_parsed = pd.Series(api.LastJson['user'])[userinfo_columns]
            userinfo = userinfo.append(userinfo_parsed, ignore_index=True)
            for image_metadata in d['GraphImages']:
                if image_metadata['__typename'] != "GraphImage" or image_metadata['shortcode'] in historic_data.shortcode.values:
                    continue
                metadata_dict = {}
                metadata_dict['scraped_at'] = datetime.datetime.now()
                metadata_dict['nr_likes'] = image_metadata['edge_media_preview_like']['count']
                metadata_dict['nr_comments'] = image_metadata['edge_media_to_comment']['count']
                metadata_dict['caption'] = image_metadata['edge_media_to_caption']['edges'][0]['node']['text']
                metadata_dict['shortcode'] = image_metadata['shortcode']
                metadata_dict['username'] = image_metadata['username']
                metadata_dict['width'] = image_metadata['dimensions']['width']
                metadata_dict['height'] = image_metadata['dimensions']['height']
                metadata_dict['owner_id'] = image_metadata['owner']['id']
                metadata_dict['image_url'] = image_metadata['urls'][0]
                metadata_dict['comments_disabled'] = image_metadata['comments_disabled']
                metadata_dict['taken_at_timestamp'] = image_metadata['taken_at_timestamp']
                metadata_dict['tags'] = image_metadata['tags']
                metadata_dict['image_id'] = image_metadata['id']

                if image_metadata['location'] is not None:
                    metadata_dict['location_id'] = image_metadata['location']['id']
                    metadata_dict['location_name'] = image_metadata['location']['name']
                    if image_metadata['location']['address_json'] is not None:
                        location_json = json.loads(image_metadata['location']['address_json'])
                        metadata_dict['region_name'] = location_json['region_name']
                        metadata_dict['city_name'] = location_json['city_name']
                        metadata_dict['country_code'] = location_json['country_code']
                metadata.append(metadata_dict)
    user_df = pd.DataFrame(userinfo)
    if metadata and not user_df.empty:
        return pd.DataFrame(metadata).merge(user_df, on='username')
    else:
        return pd.DataFrame(columns=historic_data.columns)


def get_word_vectors(row):
    spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS
    text_features = nlp(row.caption)
    tokens_idxs = np.array([idx for idx, token in enumerate(text_features) if not token.is_stop])
    tokens_idxs_masked = tokens_idxs[tokens_idxs < len(text_features.vector)]
    token_vectors = text_features.vector[tokens_idxs_masked]
    token_vectors = \
        pad_sequences([token_vectors], maxlen=50, padding='post', truncating='post', value=0.0, dtype='float32')[0]
    return pd.Series(token_vectors)


def calc_dominant_color(row, debug=False):
    start_time = time.time()
    img = io.imread(f'ig_images/{row.username}/{row.shortcode}.jpg')
    imgload_time = time.time()
    pixels = np.float32(img.reshape(-1, 3))
    pixel_time = time.time()
    n_colors = 5
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 15, .2)
    flags = cv2.KMEANS_RANDOM_CENTERS
    var_set_time = time.time()

    _, labels, palette = cv2.kmeans(pixels, n_colors, None, criteria, 15, flags)
    kmeans_time = time.time()
    _, counts = np.unique(labels, return_counts=True)
    dominant = palette[np.argmax(counts)]
    end_time = time.time()
    if debug:
        print(f"""image load time: {imgload_time - start_time}
pixel time: {pixel_time - imgload_time}
variable set time: {var_set_time - pixel_time}
kmeans time: {kmeans_time - var_set_time}
end time: {end_time - kmeans_time}
total time: {end_time - start_time}
    """)
    return dominant.tolist()


def is_suitable_static(row, metadata):
    # check if image already exists somewhere else
    image_path = f'ig_images/{row.username}/{row.shortcode}.jpg'
    image_hash = str(average_hash(Image.open(image_path)))
    if image_hash in metadata.image_hash.values:
        logger.debug('hash fail')
        return False

    # check for forbidden substrings
    forbidden_substrings = ['buy now', 'limited time']
    if any(substring in row.caption for substring in forbidden_substrings) or row.comments_disabled:
        logger.debug('forbidden caption fail')
        return False

    # check if location is in amsterdam
    if city not in row.caption.lower():
        if not isinstance(row.location_id, float):
            if city not in row.location_name.lower():
                if isinstance(row.city_name, str):
                    if city not in row.city_name.lower():
                        logger.debug(f'{city} not mentioned fail')
                        return False
                else:
                    return False

    # Check if comments disabled
    if row.comments_disabled:
        logger.debug('comments disabled')
        return False
    logger.debug('success')
    return True


def train_ml():
    metadata = get_train_data()
    is_suitable_ml(metadata, train=True)


def is_suitable_ml(metadata: pd.DataFrame, test_pct=0.2, train=False):
    org_cols = metadata.columns.tolist()
    token_vectors = metadata.apply(get_word_vectors, axis=1)
    metadata = metadata.merge(token_vectors, left_index=True, right_index=True)
    colors = np.array(metadata.dominant_color.tolist())
    metadata['red'] = colors[:, 0]
    metadata['green'] = colors[:, 1]
    metadata['blue'] = colors[:, 2]
    metadata['like_ratio'] = metadata['nr_likes'] / metadata['follower_count']
    metadata['comment_ratio'] = metadata['nr_comments'] / metadata['follower_count']
    metadata['taken_at_datetime'] = pd.to_datetime(metadata['taken_at_timestamp'], unit='s')
    metadata['caption_length'] = [len(caption) for caption in metadata.caption]
    metadata = lib.add_cyclic_datepart(metadata, time=True, field_name='taken_at_datetime', drop=False)
    non_float_cols = org_cols + ['taken_at_datetime']
    x = metadata.drop(non_float_cols, axis=1)
    x['followers'] = metadata.follower_count
    x['nr_likes'] = metadata.nr_likes
    x['nr_comments'] = metadata.nr_comments

    if train:
        y = metadata.suitable
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_pct, shuffle=True)
        clf = RandomForestClassifier(100)
        clf.fit(x_train, y_train)
        logger.info(f'Test set accuracy: {clf.score(x_test, y_test)}')
        pickle.dump(clf, open(f'{artefacts_path}/model.pkl', 'wb'))
    else:
        clf = pickle.load(open(f'{artefacts_path}/model.pkl', 'rb'))
        return clf.predict(x).astype('bool').tolist()


def retrieve_data(n_images=None, scrape=True, test=False):
    logger.info(f'{"#"*10} Retrieving data {"#"*10}')

    if n_images is None:
        n_images = N_IMAGES

    s3 = lib.get_s3()
    try:
        s3.Bucket('taicapanbot').download_file('latest_stamps.txt', 'latest_stamps.txt')
    except:
        pass

    if scrape:
        script = 'instagram-scraper --login-user "{username}" --login-pass "{password}" --maximum {n_images} -f artefacts/ig_users.txt --media-types=image -d ig_images --retain-username --latest-stamps latest_stamps.txt --include-location -T "{{shortcode}}"'
        script = script.format(username=lib.ig_username, password=lib.ig_password, n_images=n_images)
        logger.info('Scraping data...')
        process = subprocess.run(script, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True,
                                 shell=True)
        logger.info(process.stdout), logger.info(process.stderr)
        logger.info('Scraping finished.')
        logging.info('Uploading latest_stamps.txt')
        s3.Bucket('taicapanbot').upload_file('latest_stamps.txt', 'latest_stamps.txt')

    logger.info('Loading old metadata...')
    metadata = get_historic_data()
#     image_hashes = get_image_hashes(metadata)
    logger.info('Loading new metadata...')
    new_metadata = get_new_metadata(metadata)

    if not new_metadata.empty:
        logger.info('Analyzing new images...')
        logger.info('Calculating dominant colors')
        new_metadata.loc[:, 'dominant_color'] =  new_metadata.progress_apply(calc_dominant_color, axis=1)
        new_metadata.loc[:, 'image_hash'] = get_image_hashes(new_metadata)
        logger.info('Performing static check...')
        suitable_with_hashes = partial(is_suitable_static, metadata=metadata)
        new_metadata['accepted_static'] = new_metadata.progress_apply(suitable_with_hashes, axis=1)
        logger.info('Performing machine learning check...')
        new_metadata.loc[:, 'accepted_ml'] = is_suitable_ml(new_metadata)
        if metadata is None:
            metadata = new_metadata
        else:
            metadata = metadata.append(new_metadata, sort=False)

        if not test:
            logger.info('Writing new metadata')
            write_historic_metadata(metadata)
        logger.info('Done.')
    else:
        logger.info('There are no new images. Skipping analysis and upload.')


if __name__ == "__main__":
    retrieve_data()
